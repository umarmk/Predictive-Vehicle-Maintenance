{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "data_paths = {\n",
    "    'ai4i2020': '../data/ai4i2020.csv',\n",
    "    'cleaned_vehicle_data': '../data/cleaned_vehicle_data.csv',\n",
    "    'engine_data': '../data/engine_data.csv',\n",
    "    'vehicle_sensor_data': '../data/vehicle_sensor_data.csv'\n",
    "}\n",
    "dfs = {name: pd.read_csv(path) for name, path in data_paths.items()}\n",
    "for name, df in dfs.items():\n",
    "    print(f'--- {name} ---')\n",
    "    print(df.head())\n",
    "    print(df.info())\n",
    "    print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data Cleaning: missing values, duplicates, outliers\n",
    "for name, df in dfs.items():\n",
    "    print(f'--- {name} ---')\n",
    "    print('Missing values per column:')\n",
    "    print(df.isnull().sum())\n",
    "    print('Number of duplicate rows:', df.duplicated().sum())\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    # Fill missing values with median for numeric columns\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "    # Fill missing categorical values with mode\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    # Simple outlier detection (Z-score for numeric columns)\n",
    "    z_scores = np.abs((df[num_cols] - df[num_cols].mean()) / df[num_cols].std())\n",
    "    outliers = (z_scores > 3).sum()\n",
    "    print('Potential outliers per column:')\n",
    "    print(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data Normalization/Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaled_dfs = {}\n",
    "for name, df in dfs.items():\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    scaled_dfs[name] = df_scaled\n",
    "    print(f'{name} - Scaled sample:')\n",
    "    print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature Engineering Example\n",
    "for name, df in dfs.items():\n",
    "    if 'mileage' in df.columns:\n",
    "        df['high_mileage'] = (df['mileage'] > 100000).astype(int)\n",
    "    if 'temperature' in df.columns:\n",
    "        df['temp_above_avg'] = (df['temperature'] > df['temperature'].mean()).astype(int)\n",
    "    print(f'Feature engineering done for {name}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
